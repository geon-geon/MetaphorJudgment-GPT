{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "모듈 설치 및 임포트"
      ],
      "metadata": {
        "id": "AmU1c48udUfi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pddkwtwu_2PI",
        "outputId": "330c4a54-e899-4362-822c-1d04ca3c85b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.5-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.5 yarl-1.9.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.0-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.7/152.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai \n",
        "!pip install pandas\n",
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openai\n",
        "import re\n",
        "import xlsxwriter\n",
        "from openpyxl import load_workbook"
      ],
      "metadata": {
        "id": "Fwj1WXy3Fyjp"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실험에 사용될 함수 정의"
      ],
      "metadata": {
        "id": "iRSzT1E_2r2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_typ_experiments(num_experiments, input_file, output_file = \"Typicality_result.xlsx\"):\n",
        "    # Phase 1: 실험 전\n",
        "    # OpenAI API KEY 불러오기\n",
        "    with open(\"OPENAI_API_KEY.txt\", \"r\") as f:\n",
        "        api_key = f.read().strip()\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    # 결과를 기록할 파일 및 시트 구축\n",
        "    if output_file is None:\n",
        "        output_file = \"Typicality_result.xlsx\"\n",
        "    try:\n",
        "        existing_file = pd.ExcelFile(output_file, engine='openpyxl')\n",
        "        existing_sheets = existing_file.sheet_names\n",
        "        num_sheets = len(existing_sheets)\n",
        "        Results = pd.ExcelWriter(output_file, engine=\"openpyxl\", mode=\"a\", if_sheet_exists='replace')\n",
        "        sheet_name_list = [f\"EXP {i}\" for i in range(num_sheets + 1, num_sheets + num_experiments + 1)]\n",
        "    except FileNotFoundError:\n",
        "        Results = pd.ExcelWriter(output_file, engine=\"openpyxl\")\n",
        "        sheet_name_list = [f\"EXP {i}\" for i in range(1, num_experiments + 1)]\n",
        "\n",
        "    for sheet_name in sheet_name_list:\n",
        "        df = pd.DataFrame(columns=[\"Item\", \"Condition\", \"Sentence\", \"Response\", \"Typicality\"])\n",
        "        df.to_excel(Results, sheet_name=sheet_name, index=False)\n",
        "\n",
        "\n",
        "    # Phase 2: 실험 시작\n",
        "    # 실험 문장 파일 읽기\n",
        "    materials = pd.read_excel(input_file)\n",
        "    num_rows, num_columns = materials.shape\n",
        "\n",
        "    # 문장 배치 무선화\n",
        "    for i in range(num_experiments):\n",
        "        sentence_order = random.sample(range(num_rows), num_rows)\n",
        "        responses = []\n",
        "        typicalities = []\n",
        "        \n",
        "        # 모든 문장에 대해 시행을 수행\n",
        "        for j, row in enumerate(sentence_order):\n",
        "            item = materials.iloc[row, 3]\n",
        "            cell_value = materials.iloc[row, num_columns - 1]\n",
        "            prompt = f'''Please judge the typicality of the following expression on a scale of 1 to 7, \n",
        "            with 1 being \"not typical at all\" and 7 being \"extremely typical\" : {cell_value}'''\n",
        "\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model = \"gpt-3.5-turbo\",\n",
        "                temperature = 0.5,\n",
        "                n = 1,\n",
        "                max_tokens = 128,\n",
        "                stop = None,\n",
        "                messages = [{\"role\" : \"system\", \"content\" : \"Your answer should contain numeric rating scale, which is the only number in your sentence.\"},\n",
        "                {\"role\" : \"user\", \"content\" : prompt}])\n",
        "            time.sleep(1)\n",
        "            response_text = response.choices[0]['message']['content']\n",
        "            responses.append(response_text)\n",
        "            progress = f\"EXP {i+1}/{num_experiments} Sentence {j+1}/{num_rows}\"\n",
        "            print(progress)\n",
        "\n",
        "            #Typicality 추출 및 저장\n",
        "            typicality = None\n",
        "            match = re.search(r\"\\b[1-7]\\b\", response_text)\n",
        "            if match:\n",
        "                typicality = int(match.group())\n",
        "            typicalities.append(typicality)\n",
        "\n",
        "    # Phase 3: 실험 결과를 파일에 저장\n",
        "        sheet_name = sheet_name_list[i]\n",
        "        df = pd.DataFrame({\n",
        "            \"Item\": materials.iloc[sentence_order, 3],\n",
        "            \"Condition\" : materials.iloc[sentence_order, 5],\n",
        "            \"Sentence\": materials.iloc[sentence_order, num_columns - 1],\n",
        "            \"Response\": responses,\n",
        "            \"Typicality\": typicalities}, columns=[\"Item\", \"Condition\", \"Sentence\", \"Response\", \"Typicality\"])\n",
        "        df.to_excel(Results, sheet_name=sheet_name, index=False)\n",
        "    Results.close()\n",
        "    print(\"Experiment completed successfully!\")"
      ],
      "metadata": {
        "id": "aQIg5zu_xLcu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_accp_experiments(num_experiments, input_file, output_file = \"Acceptability_result.xlsx\"):\n",
        "    # Phase 1: 실험 전\n",
        "    # OpenAI API KEY 불러오기\n",
        "    with open(\"OPENAI_API_KEY.txt\", \"r\") as f:\n",
        "        api_key = f.read().strip()\n",
        "    openai.api_key = api_key\n",
        "\n",
        "    # 결과를 기록할 파일 및 시트 구축\n",
        "    if output_file is None:\n",
        "        output_file = \"Acceptability_result.xlsx\"\n",
        "    try:\n",
        "        existing_file = pd.ExcelFile(output_file, engine='openpyxl')\n",
        "        existing_sheets = existing_file.sheet_names\n",
        "        num_sheets = len(existing_sheets)\n",
        "        Results = pd.ExcelWriter(output_file, engine=\"openpyxl\", mode=\"a\", if_sheet_exists='replace')\n",
        "        sheet_name_list = [f\"EXP {i}\" for i in range(num_sheets + 1, num_sheets + num_experiments + 1)]\n",
        "    except FileNotFoundError:\n",
        "        Results = pd.ExcelWriter(output_file, engine=\"openpyxl\")\n",
        "        sheet_name_list = [f\"EXP {i}\" for i in range(1, num_experiments + 1)]\n",
        "\n",
        "    for sheet_name in sheet_name_list:\n",
        "        df = pd.DataFrame(columns=[\"Item\", \"Sentence_num\", \"Sentence\", \"Response\", \"Acceptability\"])\n",
        "        df.to_excel(Results, sheet_name=sheet_name, index=False)\n",
        "\n",
        "\n",
        "    # Phase 2: 실험 시작\n",
        "    # 실험 문장 파일 읽기\n",
        "    materials = pd.read_excel(input_file)\n",
        "    num_rows, num_columns = materials.shape\n",
        "\n",
        "    # 문장 배치 무선화\n",
        "    for i in range(num_experiments):\n",
        "        sentence_order = random.sample(range(num_rows), num_rows)\n",
        "        responses = []\n",
        "        acceptabilities = []\n",
        "        \n",
        "        # 모든 문장에 대해 시행을 수행\n",
        "        for j, row in enumerate(sentence_order):\n",
        "            item = materials.iloc[row, 2]\n",
        "            cell_value = materials.iloc[row, num_columns - 1]\n",
        "            prompt = f'''Please judge the acceptability of the following expression on a scale of 1 to 7, \n",
        "            with 1 being \"not acceptable at all\" and 7 being \"extremely acceptable\" : {cell_value}'''\n",
        "\n",
        "            response = openai.ChatCompletion.create(\n",
        "                model = \"gpt-3.5-turbo\",\n",
        "                temperature = 0.5,\n",
        "                n = 1,\n",
        "                max_tokens = 256,\n",
        "                stop = None,\n",
        "                messages = [{\"role\" : \"system\", \"content\" : \"Your answer should contain numeric rating scale, which is the only number in your sentence.\"},\n",
        "                {\"role\" : \"user\", \"content\" : prompt}])\n",
        "            time.sleep(1)\n",
        "            response_text = response.choices[0]['message']['content']\n",
        "            responses.append(response_text)\n",
        "            progress = f\"EXP {i+1}/{num_experiments} Sentence {j+1}/{num_rows}\"\n",
        "            print(progress)\n",
        "\n",
        "            #Acceptablity 추출 및 저장\n",
        "            acceptablity = None\n",
        "            match = re.search(r\"\\b[1-7]\\b\", response_text)\n",
        "            if match:\n",
        "                acceptablity = int(match.group())\n",
        "            acceptabilities.append(acceptablity)\n",
        "\n",
        "    # Phase 3: 실험 결과를 파일에 저장\n",
        "        sheet_name = sheet_name_list[i]\n",
        "        df = pd.DataFrame({\n",
        "            \"Item\": materials.iloc[sentence_order, 1],\n",
        "            \"Sentence_num\" :materials.iloc[sentence_order, 2],\n",
        "            \"Sentence\": materials.iloc[sentence_order, num_columns - 1],\n",
        "            \"Response\": responses,\n",
        "            \"Acceptability\": acceptabilities}, columns=[\"Item\", \"Sentence_num\", \"Sentence\", \"Response\", \"Acceptability\"])\n",
        "        df.to_excel(Results, sheet_name=sheet_name, index=False)\n",
        "    Results.close()\n",
        "    print(\"Experiment completed successfully!\")"
      ],
      "metadata": {
        "id": "KugCge9oB0VT"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_typ_rawdata(input_file_path, output_file_name):\n",
        "    #파일 입수 및 전처리\n",
        "    input_data = pd.read_excel(input_file_path, sheet_name=None)\n",
        "    output_file_path = output_file_name \n",
        "\n",
        "    Summary = pd.ExcelWriter(output_file_path, engine='xlsxwriter')\n",
        "    exp_summary = pd.DataFrame(columns=['Item', 'Condition', 'Sentence', 'Typicality'])\n",
        "\n",
        "    for sheet_name, sheet in input_data.items():\n",
        "        sheet_sorted = sheet.sort_values('Item')\n",
        "        sheet_sorted.to_excel(Summary, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        # Item 별 Typicality 평균 계산\n",
        "        item_summary = sheet.groupby('Item').agg({'Typicality': 'mean', 'Condition': 'first', 'Sentence': 'first'}).reset_index()\n",
        "        item_summary.rename(columns={'Typicality': 'Mean_typicality'}, inplace=True)\n",
        "        exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
        "\n",
        "    # 결과 생성 및 저장\n",
        "    exp_summary = exp_summary.groupby(['Item', 'Condition', 'Sentence']).agg({'Mean_typicality': 'mean'}).reset_index()\n",
        "    exp_summary.to_excel(Summary, sheet_name='Experiment_summary', index=False)\n",
        "    Summary.close()\n",
        "    wb = load_workbook(output_file_path)\n",
        "    wb.move_sheet(wb[\"Experiment_summary\"], offset = -len(wb.sheetnames) + 1)\n",
        "    wb.save(output_file_path)\n",
        "\n",
        "def process_accp_rawdata(input_file_path, output_file_name):\n",
        "    #파일 입수 및 전처리\n",
        "    input_data = pd.read_excel(input_file_path, sheet_name=None)\n",
        "    output_file_path = output_file_name \n",
        "\n",
        "    Summary = pd.ExcelWriter(output_file_path, engine='xlsxwriter')\n",
        "    exp_summary = pd.DataFrame(columns=['Item', 'Sentence_num', 'Sentence', 'Acceptability'])\n",
        "\n",
        "    for sheet_name, sheet in input_data.items():\n",
        "        sheet_sorted = sheet.sort_values('Item')\n",
        "        sheet_sorted.to_excel(Summary, sheet_name=sheet_name, index=False)\n",
        "\n",
        "        # Item 별 acceptability 평균 계산\n",
        "        item_summary = sheet.groupby('Item').agg({'Acceptability': 'mean', 'Sentence_num': 'first', 'Sentence': 'first'}).reset_index()\n",
        "        item_summary.rename(columns={'Acceptability': 'Mean_acceptability'}, inplace=True)\n",
        "        exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
        "\n",
        "    # 결과 생성 및 저장\n",
        "    exp_summary = exp_summary.groupby(['Item', 'Sentence_num', 'Sentence']).agg({'Mean_acceptability': 'mean'}).reset_index()\n",
        "    exp_summary.to_excel(Summary, sheet_name='Experiment_summary', index=False)\n",
        "    Summary.close()\n",
        "    wb = load_workbook(output_file_path)\n",
        "    wb.move_sheet(wb[\"Experiment_summary\"], offset = -len(wb.sheetnames) + 1)\n",
        "    wb.save(output_file_path)\n"
      ],
      "metadata": {
        "id": "XBN-uAH6urSq"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "함수 실행 부분"
      ],
      "metadata": {
        "id": "Z-tD4P1gvUVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Typ_input_file = \"Typicality_Materials.xlsx\"\n",
        "Accp_input_file = \"Acceptability_Materials.xlsx\"\n",
        "run_typ_experiments(30, Typ_input_file)\n",
        "run_accp_experiments(30, Accp_input_file)\n",
        "Typ_rawdata = \"Typicality_result.xlsx\"\n",
        "Accp_rawdata = \"Acceptability_result.xlsx\"\n",
        "Typ_summary = \"Typicality_summary.xlsx\"\n",
        "Accp_summary = \"Acceptability_summary.xlsx\"\n",
        "process_typ_rawdata(Typ_rawdata,Typ_summary)\n",
        "process_accp_rawdata(Accp_rawdata,Accp_summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0cZQJfJyeEp",
        "outputId": "3443ceb5-0d5a-4b0f-ae16-e9f2ebe3ef6b"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n",
            "<ipython-input-123-945353bf3cf1>:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  exp_summary = exp_summary.append(item_summary, ignore_index=True)\n"
          ]
        }
      ]
    }
  ]
}